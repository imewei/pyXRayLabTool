name: Workflow Status Dashboard

on:
  workflow_run:
    workflows: ["*"]
    types:
      - completed
  schedule:
    # Update dashboard every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:

concurrency:
  group: status-dashboard
  cancel-in-progress: true

jobs:
  update-dashboard:
    name: Update Workflow Status Dashboard
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 1

    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
        cache: 'pip'

    - name: Install GitHub CLI and dependencies
      run: |
        # GitHub CLI should already be available
        gh --version

        python -m pip install --upgrade pip
        pip install requests python-dateutil

    - name: Generate workflow status badges
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        echo "üè∑Ô∏è Generating workflow status badges..."

        python -c "
        import subprocess
        import json
        import datetime
        from collections import defaultdict

        # Get latest workflow runs for each workflow
        result = subprocess.run([
            'gh', 'run', 'list',
            '--limit', '50',
            '--json', 'status,conclusion,workflowName,createdAt,url'
        ], capture_output=True, text=True)

        if result.returncode != 0:
            print('‚ùå Failed to fetch workflow data')
            exit(1)

        runs = json.loads(result.stdout)

        # Get latest run for each workflow
        latest_runs = {}
        for run in runs:
            workflow = run['workflowName']
            if workflow not in latest_runs:
                latest_runs[workflow] = run

        # Generate status summary
        status_summary = {
            'last_updated': datetime.datetime.now().isoformat(),
            'workflows': {}
        }

        print('üìä Current Workflow Status:')
        print('=' * 50)

        for workflow, run in latest_runs.items():
            conclusion = run['conclusion'] or run['status']
            created = run['createdAt']
            url = run['url']

            # Determine status badge
            if conclusion == 'success':
                badge = '‚úÖ'
                status = 'passing'
            elif conclusion == 'failure':
                badge = '‚ùå'
                status = 'failing'
            elif conclusion in ['cancelled', 'skipped']:
                badge = '‚è≠Ô∏è'
                status = 'skipped'
            else:
                badge = 'üîÑ'
                status = 'running'

            print(f'{badge} {workflow:30} | {status:8} | {created}')

            status_summary['workflows'][workflow] = {
                'status': status,
                'conclusion': conclusion,
                'created_at': created,
                'url': url,
                'badge': badge
            }

        # Save status summary
        with open('workflow_status.json', 'w') as f:
            json.dump(status_summary, f, indent=2)

        print(f'\\nüíæ Status saved to workflow_status.json')
        "

    - name: Generate status markdown
      run: |
        echo "üìù Generating status markdown..."

        python -c "
        import json
        import datetime

        # Load status data
        with open('workflow_status.json', 'r') as f:
            status_data = json.load(f)

        # Generate markdown
        lines = [
            '# üöÄ Workflow Status Dashboard',
            '',
            f'*Last updated: {status_data[\"last_updated\"]}*',
            '',
            '## Current Status',
            '',
            '| Workflow | Status | Last Run |',
            '|----------|--------|----------|'
        ]

        for workflow, info in sorted(status_data['workflows'].items()):
            # Format timestamp
            created = datetime.datetime.fromisoformat(info['created_at'].replace('Z', '+00:00'))
            time_str = created.strftime('%Y-%m-%d %H:%M')

            lines.append(
                f'| [{workflow}]({info[\"url\"]}) | {info[\"badge\"]} {info[\"status\"]} | {time_str} |'
            )

        # Add legend
        lines.extend([
            '',
            '## Legend',
            '',
            '- ‚úÖ **Passing**: Last run completed successfully',
            '- ‚ùå **Failing**: Last run failed',
            '- üîÑ **Running**: Currently in progress',
            '- ‚è≠Ô∏è **Skipped**: Last run was cancelled or skipped',
            '',
            '---',
            '',
            '*This dashboard is automatically updated every 6 hours and after each workflow completion.*'
        ])

        # Save markdown
        with open('WORKFLOW_STATUS.md', 'w') as f:
            f.write('\\n'.join(lines))

        print('‚úÖ Status markdown generated')
        "

    - name: Check for failing workflows
      run: |
        echo "üîç Checking for critical failures..."

        python -c "
        import json

        with open('workflow_status.json', 'r') as f:
            status_data = json.load(f)

        failing_workflows = []
        for workflow, info in status_data['workflows'].items():
            if info['status'] == 'failing':
                failing_workflows.append(workflow)

        if failing_workflows:
            print(f'üö® {len(failing_workflows)} workflows are currently failing:')
            for workflow in failing_workflows:
                print(f'   - {workflow}')

            # Set output for potential notifications
            print(f'FAILING_COUNT={len(failing_workflows)}')
        else:
            print('‚úÖ All workflows are healthy!')
            print('FAILING_COUNT=0')
        "

    - name: Upload status artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: workflow-status-dashboard
        path: |
          workflow_status.json
          WORKFLOW_STATUS.md
        retention-days: 90

    - name: Update repository status (optional)
      if: github.ref == 'refs/heads/main'
      run: |
        echo "üìä Workflow status dashboard updated"
        echo "View the latest status in the uploaded artifacts"
        echo "or check the workflow_status.json file"

  health-summary:
    name: Workflow Health Summary
    needs: update-dashboard
    runs-on: ubuntu-latest
    if: always()

    steps:
    - name: Download status data
      uses: actions/download-artifact@v4
      with:
        name: workflow-status-dashboard

    - name: Generate health summary
      run: |
        echo "üìã Workflow Health Summary"
        echo "========================="

        if [[ -f "workflow_status.json" ]]; then
          python -c "
          import json

          with open('workflow_status.json', 'r') as f:
              data = json.load(f)

          total = len(data['workflows'])
          passing = sum(1 for w in data['workflows'].values() if w['status'] == 'passing')
          failing = sum(1 for w in data['workflows'].values() if w['status'] == 'failing')
          running = sum(1 for w in data['workflows'].values() if w['status'] == 'running')

          print(f'Total workflows: {total}')
          print(f'‚úÖ Passing: {passing} ({passing/total*100:.1f}%)')
          print(f'‚ùå Failing: {failing} ({failing/total*100:.1f}%)')
          print(f'üîÑ Running: {running} ({running/total*100:.1f}%)')

          if failing == 0:
              print('\\nüéâ All workflows are healthy!')
          else:
              print(f'\\n‚ö†Ô∏è {failing} workflows need attention')
          "
        else
          echo "‚ö†Ô∏è No status data available"
        fi
